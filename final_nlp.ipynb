{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext==0.10.0"
      ],
      "metadata": {
        "id": "SIzfKGfECRwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-crf==0.7.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1R7-dwDEY2-",
        "outputId": "73920b1f-ba10-4a21-b2bd-96f032402c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-crf==0.7.2\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy.data import Field,NestedField, BucketIterator, Dataset, Example\n",
        "from torchtext.vocab import Vocab\n",
        "# from utils import read_file\n",
        "from collections import Counter\n",
        "import torch\n",
        "from random import randint\n",
        "# from augmentation import aug_replace_in_same_tag\n",
        "import random"
      ],
      "metadata": {
        "id": "sJGv-A_rDpat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(path):\n",
        "    train_data = []\n",
        "    with open(path, encoding='utf-8') as f:\n",
        "        words = []\n",
        "        tags = []\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                train_data.append([words, tags])\n",
        "                words = []\n",
        "                tags = []\n",
        "            else:\n",
        "                columns = line.split(' ')\n",
        "                words.append(columns[0])\n",
        "                tags.append(columns[-1])\n",
        "    return train_data\n",
        "\n",
        "# nếu là số sẽ chuyển về 0, ví dụ covid-19 -> covid-00 hay 20-11-2001 -> 00-00-0000\n",
        "def normalize_word(word):\n",
        "    new_word = \"\"\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            new_word += '0'\n",
        "        else:\n",
        "            new_word += char\n",
        "    return new_word\n",
        "\n",
        "def read_file(path, data_fields, aug=False):\n",
        "    # if aug:\n",
        "    #     train_data = get_data(path)\n",
        "    #     SYMPTOM_AND_DISEASE = get_instances_by_tag(train_data, 'SYMPTOM_AND_DISEASE')\n",
        "    #     JOBS = get_instances_by_tag(train_data, 'JOB')\n",
        "\n",
        "    with open(path, encoding='utf-8') as f:\n",
        "        examples = []\n",
        "        words = []\n",
        "        tags = []\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                examples.append(Example.fromlist([words, tags], data_fields))\n",
        "                words = []\n",
        "                tags = []\n",
        "            else:\n",
        "              columns = line.split(' ')\n",
        "              words.append(columns[0])\n",
        "              tags.append(columns[-1])\n",
        "\n",
        "    return Dataset(examples, data_fields)"
      ],
      "metadata": {
        "id": "rdv5VnJRBid1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqjnDwqdzD6K"
      },
      "outputs": [],
      "source": [
        "class NerDataset:\n",
        "    def __init__(self, train_path, val_path, test_path, batch_size, lower_word=True, wv_model=None, aug_train = True):\n",
        "        self.word_field = Field(lower=lower_word)\n",
        "        self.tag_field = Field(unk_token=None)\n",
        "\n",
        "        self.char_nesting_field = Field(tokenize=list)\n",
        "        self.char_field = NestedField(self.char_nesting_field)  # [batch_size, sent len, word len]\n",
        "        self.data_fields = [((\"word\", \"char\"), (self.word_field, self.char_field)),\n",
        "                            (\"tag\", self.tag_field)]\n",
        "\n",
        "        self.train_dataset = read_file(train_path, self.data_fields, aug = aug_train)\n",
        "        self.val_dataset = read_file(val_path, self.data_fields, aug = False)\n",
        "        self.test_dataset = read_file(test_path, self.data_fields, aug = False)\n",
        "\n",
        "        if wv_model:\n",
        "            # retrieve word2vec model from gensim library\n",
        "            # the file contains full word2vec model, not only key-vectors\n",
        "            self.wv_model = wv_model\n",
        "            self.embedding_dim = self.wv_model.vector_size\n",
        "            # cannot create vocab with build_vocab(),\n",
        "            # initiate vocab by building custom Counter based on word2vec model\n",
        "            word_freq = {word: wv_model.get_vecattr(word, \"count\") for word in wv_model.index_to_key}\n",
        "            word_counter = Counter(word_freq)\n",
        "            self.word_field.vocab = Vocab(word_counter)\n",
        "            # mapping each vector/embedding from word2vec model to word_field vocabs\n",
        "            vectors = []\n",
        "            for word, idx in self.word_field.vocab.stoi.items():\n",
        "                if idx > 1:\n",
        "                    vectors.append(torch.as_tensor(self.wv_model[word].tolist()))\n",
        "                else:  # 0 is unk and 1 is pad\n",
        "                    vectors.append(torch.zeros(self.embedding_dim))\n",
        "\n",
        "            self.word_field.vocab.set_vectors(\n",
        "                stoi=self.word_field.vocab.stoi,\n",
        "                # list of vector embedding, orderred according to word_field.vocab\n",
        "                vectors=vectors,\n",
        "                dim=self.embedding_dim\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            self.word_field.build_vocab(self.train_dataset.word)\n",
        "\n",
        "        self.tag_field.build_vocab(self.train_dataset.tag)\n",
        "        self.char_field.build_vocab(self.train_dataset.char)\n",
        "\n",
        "        self.train_iter, self.val_iter, self.test_iter = BucketIterator.splits(\n",
        "            datasets=(self.train_dataset,\n",
        "                      self.val_dataset,\n",
        "                      self.test_dataset),\n",
        "            batch_size=batch_size,\n",
        "            sort=False)\n",
        "\n",
        "        self.char_pad_idx = self.char_field.vocab.stoi[self.char_field.pad_token]\n",
        "        self.word_pad_idx = self.word_field.vocab.stoi[self.word_field.pad_token]\n",
        "        self.tag_pad_idx = self.tag_field.vocab.stoi[self.tag_field.pad_token]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "\n",
        "\n",
        "class Embedding_layer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 word_input_dim,\n",
        "                 word_embedding_dim,\n",
        "                 char_input_dim,\n",
        "                 char_embedding_dim,\n",
        "                 char_cnn_filter_num,\n",
        "                 char_cnn_kernel_size,\n",
        "                 word_pad_idx,\n",
        "                 char_pad_idx,\n",
        "\n",
        "                 char_emb_dropout,\n",
        "                 word_emb_dropout,\n",
        "                 cnn_dropout,\n",
        "\n",
        "                 use_char = True):\n",
        "        \"\"\"\n",
        "        :param word_input_dim: number of words in vocab, each word -> vector\n",
        "        :param word_embedding_dim: dim of word embedding vector\n",
        "        :param char_input_dim: number of characters in vocab\n",
        "        :param char_embedding_dim: dim of char embedding vector\n",
        "        :param char_cnn_filter_num:\n",
        "        :param char_cnn_kernel_size:\n",
        "        :param word_pad_idx:\n",
        "        :param char_pad_idx:\n",
        "        :param char_emb_dropout:\n",
        "        :param word_emb_dropout:\n",
        "        :param cnn_dropout:\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.word_pad_idx = word_pad_idx\n",
        "        self.char_pad_idx = char_pad_idx\n",
        "        self.word_embedding_dim = word_embedding_dim\n",
        "        self.char_embedding_dim = char_embedding_dim\n",
        "        self.use_char = use_char\n",
        "\n",
        "        # LAYER 1A: Word Embedding\n",
        "        self.word_embedding = nn.Embedding(\n",
        "            num_embeddings=word_input_dim,\n",
        "            embedding_dim=word_embedding_dim,\n",
        "            padding_idx=word_pad_idx  # the entries at padding_idx do not contribute to the gradient\n",
        "        )\n",
        "        self.word_emb_dropout = nn.Dropout(word_emb_dropout)\n",
        "\n",
        "        # LAYER 1B: Char Embedding-CNN\n",
        "        self.char_embedding = nn.Embedding(\n",
        "            num_embeddings=char_input_dim,\n",
        "            embedding_dim=char_embedding_dim,\n",
        "            padding_idx=char_pad_idx  # the entries at padding_idx do not contribute to the gradient\n",
        "        )\n",
        "        self.char_emb_dropout = nn.Dropout(char_emb_dropout)\n",
        "        self.char_cnn = nn.Conv1d(\n",
        "            in_channels=char_embedding_dim,\n",
        "            out_channels=char_embedding_dim * char_cnn_filter_num,\n",
        "            kernel_size=char_cnn_kernel_size,\n",
        "            # groups=char_embedding_dim  # different 1d conv for each embedding dim\n",
        "        )\n",
        "        self.cnn_dropout = nn.Dropout(cnn_dropout)\n",
        "\n",
        "    def forward(self, words, chars):\n",
        "        \"\"\"shape of input\n",
        "        # words = [sentence length, batch size]\n",
        "        # chars = [batch size, sentence length, word length)\n",
        "        # tags = [sentence length, batch size]\n",
        "        \"\"\"\n",
        "\n",
        "        # word_emb = [sentence length, batch size, word emb dim]\n",
        "        word_emb = self.word_emb_dropout(self.word_embedding(words))\n",
        "        # print(\"word_emb shape: \", word_emb.shape)\n",
        "\n",
        "        word_features = word_emb\n",
        "\n",
        "        if self.use_char:\n",
        "            # char_emb = [batch size, sentence length, word length, char emb dim]\n",
        "            char_emb = self.char_emb_dropout(self.char_embedding(chars))\n",
        "            # print(\"char_emb shape: \",char_emb.shape)\n",
        "\n",
        "            batch_size, sent_len, word_len, char_emb_dim = char_emb.shape\n",
        "            char_emb_cnn = torch.zeros(batch_size, sent_len, self.char_cnn.out_channels).to('cuda')\n",
        "            for word_i in range(sent_len):\n",
        "                # Embedding of word belong with character\n",
        "                # char_emb_word_i = [batch size, word length, char emb dim]\n",
        "                char_emb_word_i = char_emb[:, word_i, :, :]\n",
        "                # input of Conv1d has shape [N, C_in, L_in]\n",
        "                # -> permute:  char_emb_word_i = [batch size, char emb dim, word length]\n",
        "                char_emb_word_i = char_emb_word_i.permute(0, 2, 1)\n",
        "                # print(\"char_emb_word_i shape: \",char_emb_word_i.shape)\n",
        "\n",
        "                # char_emb_word_i_out = [batch size, out channels, word length - kernel size + 1]\n",
        "                char_emb_word_i_out = self.char_cnn(char_emb_word_i)\n",
        "                # print(\"char_emb_word_i_out shape: \", char_emb_word_i_out.shape)\n",
        "\n",
        "                # Max pooling from: [batch size, out channels, ...] --> [batch size, out channels]\n",
        "                # Character-level representation : one word (many characters) -> one vector 125-dim\n",
        "                char_emb_cnn[:, word_i, :], _ = torch.max(char_emb_word_i_out, dim=2)\n",
        "\n",
        "            # print(\"char_emb_cnn shape: \",char_emb_cnn.shape)\n",
        "            # char_emb_cnn = [batch size, sentence length, out channels]\n",
        "            char_emb_cnn = self.cnn_dropout(char_emb_cnn)\n",
        "            # because word_emb has shape [sentence length, batch size, word emb dim]\n",
        "            # -> permute char_emb_cnn to [sentence length, batch size, out channels]\n",
        "            char_emb_cnn = char_emb_cnn.permute(1, 0, 2)\n",
        "            # Concat word_emb and char_emb_cnn to get word_features\n",
        "            # Shape [sentence length, batch size, word emb dim + out channels]\n",
        "            word_features = torch.cat((word_emb, char_emb_cnn), dim=2)\n",
        "\n",
        "        return word_features\n",
        "\n",
        "    def init_embeddings(self,pretrained = None, freeze = False):\n",
        "        # initialize embedding for padding as zero\n",
        "        self.word_embedding.weight.data[self.word_pad_idx] = torch.zeros(self.word_embedding_dim)\n",
        "        if self.use_char:\n",
        "            self.char_embedding.weight.data[self.char_pad_idx] = torch.zeros(self.char_embedding_dim)\n",
        "\n",
        "        if pretrained is not None:\n",
        "            print(\"Use pretrain W2V\")\n",
        "            self.word_embedding = nn.Embedding.from_pretrained(\n",
        "                embeddings=torch.as_tensor(pretrained),\n",
        "                padding_idx=self.word_pad_idx,\n",
        "                freeze=freeze\n",
        "            )\n",
        "\n",
        "\n",
        "class CRF_layer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, fc_dropout, tag_pad_idx):\n",
        "        super().__init__()\n",
        "        self.tag_pad_idx = tag_pad_idx\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "        self.linear_dropout = nn.Dropout(fc_dropout)\n",
        "        self.crf = CRF(num_tags=output_dim)\n",
        "\n",
        "    def forward(self, lstm_features, tags = None):\n",
        "        fc_out = self.linear_dropout(self.linear(lstm_features))\n",
        "\n",
        "        # For training\n",
        "        if tags is not None:\n",
        "            mask = tags != self.tag_pad_idx\n",
        "            crf_out = self.crf.decode(fc_out, mask=mask)\n",
        "            crf_loss = -self.crf(fc_out, tags=tags, mask=mask)\n",
        "\n",
        "        # For testing\n",
        "        else:\n",
        "            crf_out = self.crf.decode(fc_out)\n",
        "            crf_loss = None\n",
        "\n",
        "        return crf_out, crf_loss\n",
        "\n",
        "    def init_crf_transitions(self, tag_list, imp_value=-1e4):\n",
        "        \"\"\"\n",
        "        :param tag_list: ['<pad>','O','B-LOCATION','I-LOCATION','B-PATIENT_ID',...]\n",
        "        :param imp_value: value that we assign for impossible transition, ex: b-location -> i-patient_id\n",
        "        \"\"\"\n",
        "        num_tags = len(tag_list)\n",
        "        for i in range(num_tags):\n",
        "            tag_name = tag_list[i]\n",
        "            # I and <pad> impossible as a start tag\n",
        "            if tag_name[0] == \"I\" or tag_name == \"<pad>\":\n",
        "                nn.init.constant_(self.crf.start_transitions[i], imp_value)\n",
        "            # No impossible as an end\n",
        "\n",
        "        prefix_dict = {}\n",
        "        for tag_position in (\"B\", \"I\", \"O\"):\n",
        "            prefix_dict[tag_position] = [i for i, tag in enumerate(tag_list) if tag[0] == tag_position]\n",
        "        # prefix_dict =\n",
        "        # {'B': [2, 4, 5, 9, 10, 11, 12, 13, 14, 15],\n",
        "        #  'I': [3, 6, 7, 8, 16, 17, 18, 19, 20],\n",
        "        #  'O': [1]}\n",
        "\n",
        "        # init impossible transitions between positions\n",
        "        impossible_transitions_position = {\"O\": \"I\"}\n",
        "        for prefix_1, prefix_2 in impossible_transitions_position.items():\n",
        "            for i in prefix_dict[prefix_1]:\n",
        "                for j in prefix_dict[prefix_2]:\n",
        "                    nn.init.constant_(self.crf.transitions[i, j], imp_value)\n",
        "\n",
        "        # init impossible B and I transition to different entity types\n",
        "        impossible_transitions_tags = {\"B\": \"I\", \"I\": \"I\"}\n",
        "        for prefix_1, prefix_2 in impossible_transitions_tags.items():\n",
        "            for i in prefix_dict[prefix_1]:\n",
        "                for j in prefix_dict[prefix_2]:\n",
        "                    if tag_list[i].split(\"-\")[1] != tag_list[j].split(\"-\")[1]:\n",
        "                        nn.init.constant_(self.crf.transitions[i, j], imp_value)\n",
        "\n",
        "\n",
        "class lstm_crf(nn.Module):\n",
        "    def __init__(self,\n",
        "                 word_input_dim,\n",
        "                 word_embedding_dim,\n",
        "                 char_input_dim,\n",
        "                 char_embedding_dim,\n",
        "                 char_cnn_filter_num,\n",
        "                 char_cnn_kernel_size,\n",
        "                 lstm_hidden_dim,\n",
        "                 output_dim,\n",
        "                 lstm_layers,\n",
        "\n",
        "                 char_emb_dropout,\n",
        "                 word_emb_dropout,\n",
        "                 cnn_dropout,\n",
        "                 lstm_dropout,\n",
        "                 fc_dropout,\n",
        "\n",
        "                 word_pad_idx,\n",
        "                 char_pad_idx,\n",
        "                 tag_pad_idx,\n",
        "\n",
        "                 use_char = True):\n",
        "        super().__init__()\n",
        "        self.word_pad_idx = word_pad_idx\n",
        "        self.tag_pad_idx = tag_pad_idx\n",
        "        self.char_pad_idx = char_pad_idx\n",
        "        self.word_embedding_dim = word_embedding_dim\n",
        "        self.char_embedding_dim = char_embedding_dim\n",
        "\n",
        "        self.embedding_layer = Embedding_layer(word_input_dim=word_input_dim,\n",
        "                                               word_embedding_dim=word_embedding_dim,\n",
        "                                               char_input_dim=char_input_dim,\n",
        "                                               char_embedding_dim=char_embedding_dim,\n",
        "                                               char_cnn_filter_num=char_cnn_filter_num,\n",
        "                                               char_cnn_kernel_size=char_cnn_kernel_size,\n",
        "                                               word_pad_idx=word_pad_idx,\n",
        "                                               char_pad_idx=char_pad_idx,\n",
        "\n",
        "                                               char_emb_dropout=char_emb_dropout,\n",
        "                                               word_emb_dropout=word_emb_dropout,\n",
        "                                               cnn_dropout=cnn_dropout,\n",
        "                                               use_char=use_char,\n",
        "                                               )\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=word_embedding_dim + use_char*(char_embedding_dim * char_cnn_filter_num),\n",
        "            hidden_size=lstm_hidden_dim,\n",
        "            num_layers=lstm_layers,\n",
        "            bidirectional=True,\n",
        "            dropout=lstm_dropout if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        self.crf_layer = CRF_layer(input_dim=lstm_hidden_dim * lstm_layers,\n",
        "                                   output_dim=output_dim,\n",
        "                                   fc_dropout=fc_dropout,\n",
        "                                   tag_pad_idx=tag_pad_idx)\n",
        "\n",
        "        for name, param in self.named_parameters():\n",
        "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "\n",
        "    def forward(self, words, chars, tags=None):\n",
        "        word_features = self.embedding_layer(words, chars)\n",
        "        # lstm_features = [sentence length, batch size, hidden dim * 2]\n",
        "        lstm_features, _ = self.lstm(word_features)\n",
        "        crf_out, crf_loss = self.crf_layer(lstm_features, tags)\n",
        "\n",
        "        return crf_out, crf_loss\n",
        "\n",
        "    def init_crf_transitions(self, tag_list):\n",
        "        self.crf_layer.init_crf_transitions(tag_list, imp_value=-1e4)\n",
        "\n",
        "    def init_embeddings(self,pretrained = None, freeze = False):\n",
        "        self.embedding_layer.init_embeddings(pretrained = pretrained, freeze = freeze)\n",
        "\n",
        "    def save_state(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load_state(self, path):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "\n",
        "class lstm_attention_crf(nn.Module):\n",
        "    def __init__(self,\n",
        "                 word_input_dim,\n",
        "                 word_embedding_dim,\n",
        "                 char_input_dim,\n",
        "                 char_embedding_dim,\n",
        "                 char_cnn_filter_num,\n",
        "                 char_cnn_kernel_size,\n",
        "                 lstm_hidden_dim,\n",
        "                 output_dim,\n",
        "                 lstm_layers,\n",
        "                 attn_heads,\n",
        "\n",
        "                 char_emb_dropout,\n",
        "                 word_emb_dropout,\n",
        "                 cnn_dropout,\n",
        "                 lstm_dropout,\n",
        "                 fc_dropout,\n",
        "                 attn_dropout,\n",
        "\n",
        "                 word_pad_idx,\n",
        "                 char_pad_idx,\n",
        "                 tag_pad_idx,\n",
        "\n",
        "                 use_char = True):\n",
        "        super().__init__()\n",
        "        self.word_pad_idx = word_pad_idx\n",
        "        self.tag_pad_idx = tag_pad_idx\n",
        "        self.char_pad_idx = char_pad_idx\n",
        "        self.word_embedding_dim = word_embedding_dim\n",
        "        self.char_embedding_dim = char_embedding_dim\n",
        "\n",
        "        self.embedding_layer = Embedding_layer(word_input_dim=word_input_dim,\n",
        "                                               word_embedding_dim=word_embedding_dim,\n",
        "                                               char_input_dim=char_input_dim,\n",
        "                                               char_embedding_dim=char_embedding_dim,\n",
        "                                               char_cnn_filter_num=char_cnn_filter_num,\n",
        "                                               char_cnn_kernel_size=char_cnn_kernel_size,\n",
        "                                               word_pad_idx=word_pad_idx,\n",
        "                                               char_pad_idx=char_pad_idx,\n",
        "\n",
        "                                               char_emb_dropout=char_emb_dropout,\n",
        "                                               word_emb_dropout=word_emb_dropout,\n",
        "                                               cnn_dropout=cnn_dropout,\n",
        "                                               use_char=use_char,\n",
        "                                               )\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=word_embedding_dim + use_char*(char_embedding_dim * char_cnn_filter_num),\n",
        "            hidden_size=lstm_hidden_dim,\n",
        "            num_layers=lstm_layers,\n",
        "            bidirectional=True,\n",
        "            dropout=lstm_dropout if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        self.attn = nn.MultiheadAttention(\n",
        "            embed_dim=lstm_hidden_dim * lstm_layers,\n",
        "            num_heads=attn_heads,\n",
        "            dropout=attn_dropout\n",
        "        )\n",
        "\n",
        "        self.crf_layer = CRF_layer(input_dim=lstm_hidden_dim * lstm_layers,\n",
        "                                   output_dim=output_dim,\n",
        "                                   fc_dropout=fc_dropout,\n",
        "                                   tag_pad_idx=tag_pad_idx)\n",
        "\n",
        "        for name, param in self.named_parameters():\n",
        "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "\n",
        "    def forward(self, words, chars, tags=None):\n",
        "        word_features = self.embedding_layer(words, chars)\n",
        "        # lstm_features = [sentence length, batch size, hidden dim * 2]\n",
        "        lstm_features, _ = self.lstm(word_features)\n",
        "\n",
        "        ### BEGIN MODIFIED SECTION: ATTENTION ###\n",
        "        # create masking for paddings\n",
        "        # key_padding_mask = [batch size, sentence length]\n",
        "        key_padding_mask = torch.as_tensor(words == self.word_pad_idx).permute(1, 0)\n",
        "        # attn_out = [sentence length, batch size, hidden dim * 2]\n",
        "        # attn_weight = [batch size, sentence length, sentence length]\n",
        "        attn_out, attn_weight = self.attn(lstm_features, lstm_features, lstm_features, key_padding_mask=key_padding_mask)\n",
        "\n",
        "        crf_out, crf_loss = self.crf_layer(attn_out, tags)\n",
        "\n",
        "        return crf_out, crf_loss\n",
        "\n",
        "    def init_crf_transitions(self, tag_list):\n",
        "        self.crf_layer.init_crf_transitions(tag_list, imp_value=-1e4)\n",
        "\n",
        "    def init_embeddings(self,pretrained = None, freeze = False):\n",
        "        self.embedding_layer.init_embeddings(pretrained = pretrained, freeze = freeze)\n",
        "\n",
        "    def save_state(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load_state(self, path):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "jBnUdpdYESAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "class Trainer(object):\n",
        "    def __init__(self, model, data, optimizer, device, loss_fn_cls=None, path='model.pt'):\n",
        "        self.device = device\n",
        "        self.model = model.to(device)\n",
        "        self.data = data\n",
        "        self.optimizer = optimizer(model.parameters())\n",
        "        self.path = path\n",
        "\n",
        "    def word_accuracy(self, preds, y):\n",
        "        assert len(preds) == len(y)\n",
        "        flatten_preds = [pred for sent_pred in preds for pred in sent_pred]\n",
        "        flatten_y = [tag for sent_tag in y for tag in sent_tag]\n",
        "        correct = [pred == tag for pred, tag in zip(flatten_preds, flatten_y)]\n",
        "        return sum(correct) / len(correct) if len(correct) > 0 else 0\n",
        "\n",
        "    def f1_score(self, preds, y, full_report=False):\n",
        "        index_o = self.data.tag_field.vocab.stoi[\"O\"]\n",
        "        # take all labels except padding and \"O\"\n",
        "        positive_labels = [i for i in range(len(self.data.tag_field.vocab.itos))\n",
        "                           if i not in (self.data.tag_pad_idx, index_o)]\n",
        "\n",
        "        flatten_pred = [pred for sent_pred in preds for pred in sent_pred]\n",
        "        flatten_y = [tag for sent_tag in y for tag in sent_tag]\n",
        "        if full_report:\n",
        "            # take all names except padding and \"O\"\n",
        "            positive_names = [self.data.tag_field.vocab.itos[i]\n",
        "                              for i in range(len(self.data.tag_field.vocab.itos))\n",
        "                              if i not in (self.data.tag_pad_idx, index_o)]\n",
        "\n",
        "            print(classification_report(\n",
        "                y_true=flatten_y,\n",
        "                y_pred=flatten_pred,\n",
        "                labels=positive_labels,\n",
        "                target_names=positive_names\n",
        "            ))\n",
        "\n",
        "        return f1_score(\n",
        "            y_true=flatten_y,\n",
        "            y_pred=flatten_pred,\n",
        "            labels=positive_labels,\n",
        "            average=\"micro\"\n",
        "        )\n",
        "\n",
        "    def sent_accuracy(self, preds, y):\n",
        "        assert len(preds) == len(y)\n",
        "        count = 0\n",
        "        for i in range(len(preds)):\n",
        "            if preds[i] == y[i]:\n",
        "                count += 1\n",
        "\n",
        "        return count / len(preds)\n",
        "\n",
        "    def train(self, N):\n",
        "        history = {\n",
        "            \"num_params\": self.model.count_parameters(),\n",
        "\n",
        "            'train_loss': [],\n",
        "            'val_loss': [],\n",
        "\n",
        "            'train_f1': [],\n",
        "            'val_f1': [],\n",
        "\n",
        "            'train_sent_acc': [],\n",
        "            'val_sent_acc': [],\n",
        "        }\n",
        "\n",
        "        lr_scheduling = ReduceLROnPlateau(\n",
        "            optimizer=self.optimizer,\n",
        "            patience=5,\n",
        "            factor=0.3,\n",
        "            mode=\"max\",\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        previous_f1 = 0\n",
        "        for epoch in range(N):\n",
        "            epoch_loss = 0\n",
        "            true_tags_epoch = []\n",
        "            pred_tags_epoch = []\n",
        "            self.model.train()\n",
        "            for batch in self.data.train_iter:\n",
        "                # words = [sent len, batch size]\n",
        "                words = batch.word.to(self.device)\n",
        "                # chars = [batch size, sent len, char len]\n",
        "                chars = batch.char.to(self.device)\n",
        "                # tags = [sent len, batch size]\n",
        "                true_tags = batch.tag.to(self.device)\n",
        "\n",
        "                pred_tags_list, batch_loss = self.model(words, chars, true_tags)\n",
        "                pred_tags_epoch += pred_tags_list\n",
        "                # to calculate the loss and f1, we flatten true tags\n",
        "                true_tags_epoch += [\n",
        "                    [tag for tag in sent_tag if tag != self.data.tag_pad_idx]\n",
        "                    for sent_tag in true_tags.permute(1, 0).tolist()\n",
        "                ]\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += batch_loss.item()\n",
        "\n",
        "            epoch_f1 = self.f1_score(pred_tags_epoch, true_tags_epoch, full_report=False)\n",
        "            epoch_loss = epoch_loss / len(self.data.train_iter)\n",
        "            epoch_sent_acc = self.sent_accuracy(pred_tags_epoch, true_tags_epoch)\n",
        "\n",
        "            history['train_loss'].append(epoch_loss)\n",
        "            history['train_f1'].append(epoch_f1)\n",
        "            history['train_sent_acc'].append(epoch_sent_acc)\n",
        "\n",
        "            print(\"Epoch \", epoch)\n",
        "            print(\n",
        "                f\"\\tTrain F1: {epoch_f1 * 100:.2f} | Train loss: {epoch_loss:.2f} | Sent acc: {epoch_sent_acc * 100: .2f}\")\n",
        "\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                epoch_loss_val = 0\n",
        "                true_tags_epoch_val = []\n",
        "                pred_tags_epoch_val = []\n",
        "                val_iter = self.data.val_iter\n",
        "                for batch in val_iter:\n",
        "                    words = batch.word.to(self.device)\n",
        "                    chars = batch.char.to(self.device)\n",
        "                    true_tags = batch.tag.to(self.device)\n",
        "                    pred_tags, batch_loss = self.model(words, chars, true_tags)\n",
        "                    pred_tags_epoch_val += pred_tags\n",
        "                    true_tags_epoch_val += [\n",
        "                        [tag for tag in sent_tag if tag != self.data.tag_pad_idx]\n",
        "                        for sent_tag in true_tags.permute(1, 0).tolist()\n",
        "                    ]\n",
        "                    epoch_loss_val += batch_loss.item()\n",
        "\n",
        "            epoch_loss_val = epoch_loss_val / len(val_iter)\n",
        "            epoch_f1_val = self.f1_score(pred_tags_epoch_val, true_tags_epoch_val)\n",
        "            epoch_sent_acc_val = self.sent_accuracy(pred_tags_epoch_val, true_tags_epoch_val)\n",
        "\n",
        "            lr_scheduling.step(epoch_f1_val)\n",
        "\n",
        "\n",
        "\n",
        "            print(\n",
        "                f\"\\tVal F1: {epoch_f1_val * 100:.2f} | Val loss: {epoch_loss_val:.2f} | Sent acc: {epoch_sent_acc_val * 100: .2f}\")\n",
        "\n",
        "            if epoch == N-1 and self.path:\n",
        "            # if epoch > 0 and epoch_f1_val > max(history['val_f1']):\n",
        "            # if epoch_f1_val > previous_f1:\n",
        "            #     print(f\"F1 score increases from {max(history['val_f1'])*100: .2f}% to {epoch_f1_val*100: .2f}%, saved model\")\n",
        "                print(f\"model is saved in {self.path}\")\n",
        "                torch.save({\n",
        "                    # 'epoch': epoch,\n",
        "                    'model_state_dict': self.model.state_dict(),\n",
        "                    # 'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                    # 'loss': loss\n",
        "                }, self.path)\n",
        "\n",
        "            history['val_loss'].append(epoch_loss_val)\n",
        "            history['val_f1'].append(epoch_f1_val)\n",
        "            history['val_sent_acc'].append(epoch_sent_acc_val)\n",
        "            # previous_f1 = epoch_f1_val\n",
        "\n",
        "            print(\"-----------------------------------------------------\")\n",
        "        return history"
      ],
      "metadata": {
        "id": "VpbW7rZTEpV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = NerDataset(train_path='/content/drive/MyDrive/NLP-20212/Conll_data/train_1.conll',\n",
        "                 val_path='/content/drive/MyDrive/NLP-20212/Conll_data/dev_1.conll',\n",
        "                 test_path='/content/drive/MyDrive/NLP-20212/Conll_data/test_1.conll',\n",
        "                 batch_size=64,\n",
        "                 lower_word = True,\n",
        "                 wv_model = None,\n",
        "                 aug_train=False)"
      ],
      "metadata": {
        "id": "puMHWbIgITMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus.word_field.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqK2lVjgIV5v",
        "outputId": "eab16c3b-a15c-4617-941d-ff4277e61a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7910"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "model = lstm_crf(\n",
        "    word_input_dim=len(corpus.word_field.vocab),\n",
        "    word_embedding_dim=300,\n",
        "    char_embedding_dim=50,\n",
        "    char_input_dim=len(corpus.char_field.vocab),\n",
        "    char_cnn_filter_num=5,\n",
        "    char_cnn_kernel_size=3,\n",
        "    lstm_hidden_dim=400,\n",
        "    output_dim=len(corpus.tag_field.vocab),\n",
        "    lstm_layers=2,\n",
        "    char_emb_dropout=0.5,\n",
        "    word_emb_dropout=0.5,\n",
        "    cnn_dropout=0.0,\n",
        "    lstm_dropout=0.0,\n",
        "    fc_dropout=0.33,\n",
        "    word_pad_idx=corpus.word_pad_idx,\n",
        "    char_pad_idx=corpus.char_pad_idx,\n",
        "    tag_pad_idx=corpus.tag_pad_idx,\n",
        "\n",
        "    use_char= True\n",
        ")\n",
        "\n",
        "\n",
        "# model.init_embeddings(\n",
        "#     pretrain=corpus.word_field.vocab.vectors,\n",
        "#     freeze=True\n",
        "# )\n",
        "\n",
        "model.init_embeddings()\n",
        "\n",
        "# CRF transitions initialization for impossible transitions\n",
        "model.init_crf_transitions(\n",
        "        tag_list=corpus.tag_field.vocab.itos\n",
        ")\n",
        "\n",
        "print(\"Number of parameters: \",sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    data=corpus,\n",
        "    optimizer=Adam,\n",
        "    device = 'cuda',\n",
        "    path='model.pt'\n",
        ")\n",
        "\n",
        "history =  trainer.train(30)\n",
        "\n",
        "print(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMhEArlJIXLS",
        "outputId": "c3a22f14-c093-4978-c156-ebd00f904aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters:  9327250\n",
            "Epoch  0\n",
            "\tTrain F1: 25.83 | Train loss: 2308.01 | Sent acc:  0.88\n",
            "\tVal F1: 56.49 | Val loss: 959.18 | Sent acc:  6.68\n",
            "-----------------------------------------------------\n",
            "Epoch  1\n",
            "\tTrain F1: 51.71 | Train loss: 1524.20 | Sent acc:  3.04\n",
            "\tVal F1: 64.70 | Val loss: 775.41 | Sent acc:  13.89\n",
            "-----------------------------------------------------\n",
            "Epoch  2\n",
            "\tTrain F1: 61.19 | Train loss: 1256.99 | Sent acc:  6.60\n",
            "\tVal F1: 71.45 | Val loss: 662.69 | Sent acc:  19.17\n",
            "-----------------------------------------------------\n",
            "Epoch  3\n",
            "\tTrain F1: 66.86 | Train loss: 1059.79 | Sent acc:  10.58\n",
            "\tVal F1: 70.32 | Val loss: 676.51 | Sent acc:  20.73\n",
            "-----------------------------------------------------\n",
            "Epoch  4\n",
            "\tTrain F1: 70.97 | Train loss: 912.55 | Sent acc:  14.39\n",
            "\tVal F1: 73.24 | Val loss: 606.47 | Sent acc:  23.36\n",
            "-----------------------------------------------------\n",
            "Epoch  5\n",
            "\tTrain F1: 74.18 | Train loss: 801.73 | Sent acc:  18.52\n",
            "\tVal F1: 72.92 | Val loss: 611.90 | Sent acc:  23.52\n",
            "-----------------------------------------------------\n",
            "Epoch  6\n",
            "\tTrain F1: 77.11 | Train loss: 698.17 | Sent acc:  22.04\n",
            "\tVal F1: 73.99 | Val loss: 603.68 | Sent acc:  24.56\n",
            "-----------------------------------------------------\n",
            "Epoch  7\n",
            "\tTrain F1: 79.33 | Train loss: 619.06 | Sent acc:  25.67\n",
            "\tVal F1: 73.40 | Val loss: 618.96 | Sent acc:  24.93\n",
            "-----------------------------------------------------\n",
            "Epoch  8\n",
            "\tTrain F1: 81.57 | Train loss: 546.69 | Sent acc:  28.84\n",
            "\tVal F1: 74.50 | Val loss: 628.46 | Sent acc:  25.73\n",
            "-----------------------------------------------------\n",
            "Epoch  9\n",
            "\tTrain F1: 83.26 | Train loss: 488.56 | Sent acc:  31.82\n",
            "\tVal F1: 74.90 | Val loss: 610.48 | Sent acc:  26.28\n",
            "-----------------------------------------------------\n",
            "Epoch  10\n",
            "\tTrain F1: 84.90 | Train loss: 438.22 | Sent acc:  34.90\n",
            "\tVal F1: 74.36 | Val loss: 630.30 | Sent acc:  27.18\n",
            "-----------------------------------------------------\n",
            "Epoch  11\n",
            "\tTrain F1: 86.32 | Train loss: 390.71 | Sent acc:  37.36\n",
            "\tVal F1: 74.16 | Val loss: 623.95 | Sent acc:  27.04\n",
            "-----------------------------------------------------\n",
            "Epoch  12\n",
            "\tTrain F1: 87.61 | Train loss: 352.34 | Sent acc:  39.85\n",
            "\tVal F1: 75.13 | Val loss: 618.95 | Sent acc:  27.34\n",
            "-----------------------------------------------------\n",
            "Epoch  13\n",
            "\tTrain F1: 88.38 | Train loss: 320.89 | Sent acc:  41.71\n",
            "\tVal F1: 73.25 | Val loss: 703.14 | Sent acc:  25.96\n",
            "-----------------------------------------------------\n",
            "Epoch  14\n",
            "\tTrain F1: 89.38 | Train loss: 292.70 | Sent acc:  44.40\n",
            "\tVal F1: 74.42 | Val loss: 693.32 | Sent acc:  27.02\n",
            "-----------------------------------------------------\n",
            "Epoch  15\n",
            "\tTrain F1: 90.30 | Train loss: 266.01 | Sent acc:  46.89\n",
            "\tVal F1: 74.78 | Val loss: 672.24 | Sent acc:  27.71\n",
            "-----------------------------------------------------\n",
            "Epoch  16\n",
            "\tTrain F1: 91.31 | Train loss: 243.91 | Sent acc:  49.34\n",
            "\tVal F1: 74.67 | Val loss: 692.44 | Sent acc:  27.23\n",
            "-----------------------------------------------------\n",
            "Epoch  17\n",
            "\tTrain F1: 92.06 | Train loss: 222.02 | Sent acc:  51.42\n",
            "\tVal F1: 74.67 | Val loss: 723.36 | Sent acc:  27.99\n",
            "-----------------------------------------------------\n",
            "Epoch  18\n",
            "\tTrain F1: 92.91 | Train loss: 203.42 | Sent acc:  54.03\n",
            "Epoch    19: reducing learning rate of group 0 to 3.0000e-04.\n",
            "\tVal F1: 74.81 | Val loss: 733.05 | Sent acc:  27.74\n",
            "-----------------------------------------------------\n",
            "Epoch  19\n",
            "\tTrain F1: 94.72 | Train loss: 165.18 | Sent acc:  59.65\n",
            "\tVal F1: 75.59 | Val loss: 754.93 | Sent acc:  28.29\n",
            "-----------------------------------------------------\n",
            "Epoch  20\n",
            "\tTrain F1: 95.43 | Train loss: 150.01 | Sent acc:  61.83\n",
            "\tVal F1: 75.98 | Val loss: 770.56 | Sent acc:  29.39\n",
            "-----------------------------------------------------\n",
            "Epoch  21\n",
            "\tTrain F1: 95.88 | Train loss: 141.08 | Sent acc:  64.05\n",
            "\tVal F1: 76.20 | Val loss: 815.71 | Sent acc:  28.17\n",
            "-----------------------------------------------------\n",
            "Epoch  22\n",
            "\tTrain F1: 96.10 | Train loss: 136.38 | Sent acc:  64.85\n",
            "\tVal F1: 75.88 | Val loss: 843.01 | Sent acc:  27.80\n",
            "-----------------------------------------------------\n",
            "Epoch  23\n",
            "\tTrain F1: 96.33 | Train loss: 129.31 | Sent acc:  65.75\n",
            "\tVal F1: 75.69 | Val loss: 852.98 | Sent acc:  27.76\n",
            "-----------------------------------------------------\n",
            "Epoch  24\n",
            "\tTrain F1: 96.49 | Train loss: 124.44 | Sent acc:  66.92\n",
            "\tVal F1: 76.04 | Val loss: 883.60 | Sent acc:  28.47\n",
            "-----------------------------------------------------\n",
            "Epoch  25\n",
            "\tTrain F1: 96.66 | Train loss: 119.15 | Sent acc:  67.25\n",
            "\tVal F1: 76.21 | Val loss: 906.51 | Sent acc:  28.24\n",
            "-----------------------------------------------------\n",
            "Epoch  26\n",
            "\tTrain F1: 96.71 | Train loss: 115.77 | Sent acc:  68.48\n",
            "\tVal F1: 76.07 | Val loss: 887.34 | Sent acc:  29.19\n",
            "-----------------------------------------------------\n",
            "Epoch  27\n",
            "\tTrain F1: 96.88 | Train loss: 111.74 | Sent acc:  68.97\n",
            "\tVal F1: 75.88 | Val loss: 912.81 | Sent acc:  28.63\n",
            "-----------------------------------------------------\n",
            "Epoch  28\n",
            "\tTrain F1: 97.04 | Train loss: 109.15 | Sent acc:  69.06\n",
            "\tVal F1: 76.41 | Val loss: 918.87 | Sent acc:  28.17\n",
            "-----------------------------------------------------\n",
            "Epoch  29\n",
            "\tTrain F1: 97.17 | Train loss: 104.57 | Sent acc:  70.76\n",
            "\tVal F1: 75.95 | Val loss: 950.61 | Sent acc:  28.27\n",
            "model is saved in model.pt\n",
            "-----------------------------------------------------\n",
            "{'num_params': 9327250, 'train_loss': [2308.009450785319, 1524.2021995544433, 1256.9916847229003, 1059.7858177820842, 912.5457146962484, 801.7308694203695, 698.1702260335286, 619.0619917551677, 546.6924996058146, 488.55929438273114, 438.2240344365438, 390.70857664744057, 352.3425095240275, 320.88773043950397, 292.6990083058675, 266.0112950007121, 243.91420186360676, 222.0150324821472, 203.41840794881185, 165.17956523895265, 150.0072631518046, 141.08142703374227, 136.38131694793702, 129.31241086324056, 124.44179059664408, 119.15162905057271, 115.77470655441284, 111.74071261088054, 109.14719743728638, 104.5654355843862], 'val_loss': [959.1754123463351, 775.4138120763442, 662.688959458295, 676.5140192368451, 606.4736153097714, 611.8993135340073, 603.6781369377585, 618.9636872235467, 628.4589430865119, 610.482666015625, 630.301991631003, 623.953197703642, 618.9490814208984, 703.1355720968808, 693.3200562421014, 672.2413056317498, 692.4417881685144, 723.359582788804, 733.0530135210822, 754.9280952004825, 770.557560191435, 815.7102005902459, 843.0076015696806, 852.9760616526884, 883.6007268569049, 906.5058441162109, 887.3398042566636, 912.8088800766889, 918.8735961914062, 950.613587323357], 'train_f1': [0.25834711829588003, 0.5170588270884131, 0.6118674123584776, 0.6685853765164487, 0.7097444560234064, 0.7418087621654315, 0.7710683436513568, 0.7933092921735617, 0.8157125101655643, 0.8326447551243744, 0.8490304709141273, 0.8632320476860504, 0.8761443851915786, 0.8838466427650213, 0.8938317168681205, 0.9029629881091623, 0.9130789382630616, 0.9206432576892776, 0.929138336011868, 0.9471648210401423, 0.9543448156482603, 0.9588400779052154, 0.9609501340416257, 0.9632954633279234, 0.9648810407083149, 0.9665892740656467, 0.9671484888304862, 0.9687759015278036, 0.9704326097914728, 0.9717407570014285], 'val_f1': [0.5649232718221271, 0.6469926682094427, 0.7144530746006761, 0.7032449274260962, 0.7323858578150834, 0.7291729208537919, 0.7399340542311789, 0.7339857284276522, 0.7449578338390526, 0.7490192008303062, 0.7435702929348561, 0.7416372659146403, 0.751321811456396, 0.7325414609993517, 0.744197279375863, 0.7478179502508252, 0.7466755530165984, 0.7467276437966811, 0.7480918402220404, 0.7558962824513329, 0.7597813041738898, 0.761990345029362, 0.7588486332411408, 0.7568591351088255, 0.7603844688148368, 0.7621264995704149, 0.7607251435649139, 0.75883885966635, 0.7640523641631426, 0.7595388723371368], 'train_sent_acc': [0.00878803777544596, 0.030430220356768102, 0.06597586568730325, 0.10584994753410283, 0.14388772298006297, 0.1852046169989507, 0.2203567681007345, 0.2566894018887723, 0.28843126967471144, 0.318205666316894, 0.3490293809024134, 0.37355718782791186, 0.3984784889821616, 0.41710388247639035, 0.44399265477439664, 0.4689139559286464, 0.4934417628541448, 0.5141657922350472, 0.5402675760755509, 0.5965372507869885, 0.6183105981112277, 0.6404774396642182, 0.6484784889821616, 0.6575288562434418, 0.669202518363064, 0.6724816369359916, 0.6848111227701994, 0.6896642182581322, 0.690582371458552, 0.7076337880377754], 'val_sent_acc': [0.06680488366735775, 0.13890808569454044, 0.1916609076249712, 0.2073255010366275, 0.23358673116793366, 0.235199262842663, 0.24556553789449437, 0.24925132457958996, 0.2573139829532366, 0.26284266298088, 0.2718267680258005, 0.27044459801888965, 0.2734392997005298, 0.25961759963142134, 0.27021423635107117, 0.27712508638562544, 0.2722874913614375, 0.27988942639944714, 0.2773554480534439, 0.2828841280810873, 0.2939414881363741, 0.2817323197419949, 0.27804653305689936, 0.2775858097212624, 0.2847270214236351, 0.28242340474545036, 0.29186823312600785, 0.28633955309836445, 0.2817323197419949, 0.28265376641326884]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.figure(figsize=(8, 6), dpi=90)\n",
        "val_f1_his = history['val_f1']\n",
        "val_sen_acc_his = history['val_sent_acc']\n",
        "plt.plot(np.arange(30),val_f1_his, label='val_f1')\n",
        "plt.plot(np.arange(30),val_sen_acc_his,label='val_sent_acc',color = 'red')\n",
        "\n",
        "for var in (val_f1_his, val_sen_acc_his):\n",
        "    plt.annotate('%0.2f' % max(var), xy=(1, max(var)), xytext=(-25, 5), \n",
        "                 xycoords=('axes fraction', 'data'), textcoords='offset points')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "# plt.ylabel('')\n",
        "plt.title(\"F1 score & Percentage of predicted sentences correctly on validation set\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAK_QMMGQLW3",
        "outputId": "cbac2db3-359c-4715-dce5-e887e5a350cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x540 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "model = lstm_crf(\n",
        "    word_input_dim=len(corpus.word_field.vocab),\n",
        "    word_embedding_dim=300,\n",
        "    char_embedding_dim=50,\n",
        "    char_input_dim=len(corpus.char_field.vocab),\n",
        "    char_cnn_filter_num=5,\n",
        "    char_cnn_kernel_size=3,\n",
        "    lstm_hidden_dim=400,\n",
        "    output_dim=len(corpus.tag_field.vocab),\n",
        "    lstm_layers=2,\n",
        "    char_emb_dropout=0.5,\n",
        "    word_emb_dropout=0.5,\n",
        "    cnn_dropout=0.0,\n",
        "    lstm_dropout=0.0,\n",
        "    fc_dropout=0.33,\n",
        "    word_pad_idx=corpus.word_pad_idx,\n",
        "    char_pad_idx=corpus.char_pad_idx,\n",
        "    tag_pad_idx=corpus.tag_pad_idx,\n",
        "\n",
        "    use_char= True\n",
        ")\n",
        "\n",
        "checkpoint = torch.load('model.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwlXa8TXQCog",
        "outputId": "7b389964-e170-40cc-d2a5-c368eb2409bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def f1_positive(corpus, preds, y, full_report=True):\n",
        "    index_o = corpus.tag_field.vocab.stoi[\"O\"]\n",
        "    index_pad = corpus.tag_pad_idx\n",
        "    # take all labels except padding and \"O\"\n",
        "    positive_labels = [i for i in range(len(corpus.tag_field.vocab.itos))\n",
        "                       if i not in [index_pad, index_o]]\n",
        "\n",
        "    flatten_pred = [pred for sent_pred in preds for pred in sent_pred]\n",
        "    flatten_y = [tag for sent_tag in y for tag in sent_tag]\n",
        "\n",
        "    if full_report:\n",
        "        # take all names except padding and \"O\"\n",
        "        positive_names = [corpus.tag_field.vocab.itos[i] for i in positive_labels]\n",
        "\n",
        "        print(classification_report(\n",
        "            y_true=flatten_y,\n",
        "            y_pred=flatten_pred,\n",
        "            labels=positive_labels,\n",
        "            target_names=positive_names\n",
        "        ))\n",
        "\n",
        "\n",
        "    return f1_score(\n",
        "        y_true=flatten_y,\n",
        "        y_pred=flatten_pred,\n",
        "        labels=positive_labels,\n",
        "        average=\"micro\"\n",
        "    )\n",
        "    \n",
        "\n",
        "def sent_accuracy(preds, y):\n",
        "    assert len(preds) == len(y)\n",
        "    count = 0\n",
        "    for i in range(len(preds)):\n",
        "        if preds[i] == y[i]:\n",
        "            count += 1\n",
        "\n",
        "    return count / len(preds)\n",
        "\n",
        "\n",
        "\n",
        "device = 'cuda'\n",
        "model.to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    loss_test = 0\n",
        "    true_tags_test = []\n",
        "    pred_tags_test = []\n",
        "    test_iter = corpus.test_iter\n",
        "    for batch in test_iter:\n",
        "        words = batch.word.to(device)\n",
        "        chars = batch.char.to(device)\n",
        "        true_tags = batch.tag.to(device)\n",
        "        \n",
        "        pred_tags, batch_loss = model(words, chars, true_tags)\n",
        "        \n",
        "        pred_tags_test += pred_tags\n",
        "        true_tags_test += [[tag for tag in sent_tag if tag != corpus.tag_pad_idx]\n",
        "                            for sent_tag in true_tags.permute(1, 0).tolist()]\n",
        "\n",
        "print('Percentage of predicted sentences correctly on testing data: ')\n",
        "print(sent_accuracy(pred_tags_test, true_tags_test))\n",
        "print('--------------------------------------------------------------')\n",
        "f1_score = f1_positive(corpus ,pred_tags_test, true_tags_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeBvqc70IgwH",
        "outputId": "34f095d3-ce44-4f11-9d45-5c128d4f56bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of predicted sentences correctly on testing data: \n",
            "0.31731869137497143\n",
            "--------------------------------------------------------------\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "I-PERFORMANCE       0.77      0.77      0.77     18594\n",
            "    I-BATTERY       0.80      0.88      0.84     14060\n",
            "    I-GENERAL       0.75      0.75      0.75     11830\n",
            "   I-FEATURES       0.74      0.73      0.74     12416\n",
            "    I-SER&ACC       0.77      0.72      0.75      7252\n",
            "     I-CAMERA       0.78      0.87      0.82      6266\n",
            "     I-DESIGN       0.75      0.73      0.74      3410\n",
            "    B-GENERAL       0.76      0.74      0.75      3236\n",
            "B-PERFORMANCE       0.72      0.69      0.71      2736\n",
            "     I-SCREEN       0.71      0.64      0.67      2562\n",
            "    B-BATTERY       0.81      0.82      0.82      2228\n",
            "      I-PRICE       0.58      0.46      0.51      1888\n",
            "   B-FEATURES       0.68      0.66      0.67      1646\n",
            "     B-CAMERA       0.85      0.85      0.85      1234\n",
            "    B-SER&ACC       0.70      0.65      0.67      1048\n",
            "     B-DESIGN       0.77      0.72      0.74       820\n",
            "      B-PRICE       0.54      0.46      0.49       518\n",
            "     B-SCREEN       0.77      0.70      0.73       552\n",
            "    I-STORAGE       0.69      0.46      0.55       376\n",
            "    B-STORAGE       0.65      0.38      0.48        68\n",
            "\n",
            "    micro avg       0.76      0.76      0.76     92740\n",
            "    macro avg       0.73      0.68      0.70     92740\n",
            " weighted avg       0.76      0.76      0.76     92740\n",
            "\n"
          ]
        }
      ]
    }
  ]
}